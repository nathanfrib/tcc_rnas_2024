{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoH+XH041XtgFpf9FyltCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanfrib/tcc_rnas_2024/blob/main/otimizacao_hiperparametros_mlp_lstm_gru_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGjycTTNos9g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU, Conv1D, MaxPooling1D, Flatten\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# vento_treino: vetor com todas amostras normalizadas de velocidade do vento de 2021 e 2022\n",
        "# vento_teste: vetor com todas amostras normalizadas de velocidade do vento de 2023\n",
        "\n",
        "def df_to_X_y(df, window_size):\n",
        "  df_as_numpy = df.to_numpy()\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(len(df_as_numpy) - window_size):\n",
        "    row = [[a] for a in df_as_numpy[i:i+window_size]]\n",
        "    X.append(row)\n",
        "    label = df_as_numpy[i+window_size]\n",
        "    Y.append(label)\n",
        "  return np.array(X), np.array(Y)\n",
        "\n",
        "# Gerando dados fictícios de velocidade do vento\n",
        "np.random.seed(42)\n",
        "\n",
        "# Gerar 2 anos de dados de velocidade do vento (2021 e 2022)\n",
        "n_samples_treino = int(52_560 * 2)  # Aproximadamente 105.120 amostras\n",
        "vento_treino = np.random.uniform(low=0, high=20, size=n_samples_treino)  # Velocidade do vento entre 0 e 20 m/s\n",
        "\n",
        "# Gerar 1 ano de dados de velocidade do vento (2023)\n",
        "n_samples_teste = 52_560  # Aproximadamente 52.560 amostras\n",
        "vento_teste = np.random.uniform(low=0, high=20, size=n_samples_teste)\n",
        "\n",
        "lag = 18  # 3 horas para trás\n",
        "X, y = df_to_X_y(pd.Series(vento_treino), lag)\n",
        "X_teste, y_teste = df_to_X_y(pd.Series(vento_teste), lag)\n",
        "\n",
        "# Funções para construção dos modelos via RandomSearchCV\n",
        "def create_model(model_type, lag=lag, units=50, learning_rate=0.01, dropout_rate=0.0, filters=64, kernel_size=3):\n",
        "    model = Sequential()\n",
        "    if model_type == 'lstm':\n",
        "        model.add(LSTM(units, activation='relu', input_shape=(lag, 1)))\n",
        "    elif model_type == 'mlp':\n",
        "        model.add(Dense(units, activation='relu', input_shape=(lag,)))\n",
        "    elif model_type == 'gru':\n",
        "        model.add(GRU(units, activation='relu', input_shape=(lag, 1)))\n",
        "    elif model_type == 'cnn':\n",
        "        model.add(Conv1D(filters, kernel_size, activation='relu', input_shape=(lag, 1)))\n",
        "        model.add(MaxPooling1D())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "    else:\n",
        "        raise ValueError(f\"Modelo não reconhecido: {model_type}\")\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate(model_type, X_train, y_train, X_val, y_val, params):\n",
        "    # Separar os hiperparâmetros usados na criação do modelo e no treinamento\n",
        "    model_params = {k: v for k, v in params.items() if k not in ['batch_size']}\n",
        "    training_params = {k: v for k, v in params.items() if k in ['batch_size']}\n",
        "\n",
        "    model = create_model(model_type, **model_params)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=training_params['batch_size'],\n",
        "                        validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping])\n",
        "    y_pred = model.predict(X_val)\n",
        "    score = r2_score(y_val, y_pred)\n",
        "    return score\n",
        "\n",
        "# Definição dos espaços de busca para os hiperparâmetros\n",
        "param_dist_lstm = {\n",
        "    'units': [50, 100, 200],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'dropout_rate': [0.0, 0.2, 0.4]\n",
        "}\n",
        "\n",
        "param_dist_mlp = {\n",
        "    'units': [50, 100, 200],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'dropout_rate': [0.0, 0.2, 0.4]\n",
        "}\n",
        "\n",
        "param_dist_gru = {\n",
        "    'units': [50, 100, 200],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'dropout_rate': [0.0, 0.2, 0.4]\n",
        "}\n",
        "\n",
        "param_dist_cnn = {\n",
        "    'filters': [32, 64, 128],\n",
        "    'kernel_size': [2, 3, 4],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'dropout_rate': [0.0, 0.2, 0.4]\n",
        "}\n",
        "\n",
        "# Função para executar a busca aleatória para cada modelo\n",
        "def random_search_cv(model_type, param_dist, X, y, n_iter=10, cv=5):\n",
        "    best_score = -np.inf\n",
        "    best_params = None\n",
        "    comb=0\n",
        "    tscv = TimeSeriesSplit(n_splits=cv)\n",
        "    for params in ParameterSampler(param_dist, n_iter=n_iter, random_state=42):\n",
        "        fold_scores = []\n",
        "        comb=comb+1\n",
        "\n",
        "        for train_index, val_index in tscv.split(X):\n",
        "            X_train, X_val = X[train_index], X[val_index]\n",
        "            y_train, y_val = y[train_index], y[val_index]\n",
        "            score = train_and_evaluate(model_type, X_train, y_train, X_val, y_val, params)\n",
        "            fold_scores.append(score)\n",
        "\n",
        "        mean_score = np.mean(fold_scores)\n",
        "        print(f\"Modelo: {model_type} | Combinação: {comb}\")\n",
        "        print(params)\n",
        "        print(f\"R2 média: {mean_score}\")\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_score, best_params\n",
        "\n",
        "# Executar a busca aleatória para cada modelo\n",
        "models = [\n",
        "    ('mlp', param_dist_mlp),\n",
        "    ('lstm', param_dist_lstm),\n",
        "    ('gru', param_dist_gru),\n",
        "    ('cnn', param_dist_cnn)\n",
        "]\n",
        "\n",
        "for model_type, param_dist in models:\n",
        "    best_score, best_params = random_search_cv(model_type, param_dist, X, y)\n",
        "    print(f\"Melhor R2 para a arquitetura {model_type}: {best_score}\")\n",
        "    print(f\"Melhores hiperparâmetros para a arquitetura {model_type}: {best_params}\")"
      ]
    }
  ]
}